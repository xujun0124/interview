------本地缓存--------------
https://coderxing.gitbooks.io/architecture-evolution/di-er-pian-ff1a-feng-kuang-yuan-shi-ren/42-xing-neng-zhi-ben-di-huan-cun/421-ying-yong-ceng-ben-di-huan-cun/4212-ehcache.html

1 Hashmap
     LinkedHashMap 改造成缓存 LRU
2 ehcache
	 Encache支持多层缓存模式，常用的有三种数据存储模式
	  堆内缓存（on-heap）  堆外缓存（Off-Heap）   磁盘缓存（Disk）

3 guava cache


Ehcache支持持久化到本地磁盘，Guava不可以

Guava cache说简单点就是一个支持LRU的ConCurrentHashMap，它没有Ehcache那么多的各种特性，只是提供了增、删、改、查、刷新规则和时效规则设定等最基本的元素



四、缓存的3 种清空策略 ：
　　１、FIFO ，first in first out (先进先出).
　　２、LFU ， Less Frequently Used (最少使用).意思是一直以来最少被使用的。缓存的元素有一个hit 属性，hit 值最小的将会被清出缓存。
　　３、LRU ，Least Recently Used(最近最少使用). (ehcache 默认值).缓存的元素有一个时间戳，当缓存容量满了，而又需要腾出地方来缓存新的元素的时候，那么现有缓存元素中时间戳离当前时间最远的元素将被清出缓存。

------缓存--------------
Memcached是一种基于内存的key-value存储，用来存储小块的任意数据（字符串、对象）

memcached作为高速运行的分布式缓存服务器，具有以下的特点。

协议简单
基于libevent的事件处理
内置内存存储方式
memcached不互相通信的分布式


LRU淘汰算法
LFU（Least Frequently Used）最近最少使用算法
　　注意LFU和LRU算法的不同之处，LRU的淘汰规则是基于访问时间，而LFU是基于访问次数的。举个简单的例子：



Memcached集群/

Magent 缓存代理  

单大体工作原理如下：

   1. magent每次写数据都会写到主memcached和从memcached上，并且向主从memcached写的算法一样;

   2. 当主memcached宕掉，magent会向从memcached中读取数据。

   3. 当主memcached恢复后，magent将重新向主memcached中读取数据；此时由于主memcached刚刚恢复，其中并无数据，因此导致部分数据无法读取，这也是magent的一大缺点

Memcahe并不提供持久机制，因为Memache的设计理念就是设计一个单纯的缓存
=================================

缓存穿透
指的是对某个一定不存在的数据进行请求，该请求将会穿透缓存到达数据库。

解决方案：

对这些不存在的数据缓存一个空数据；
对这类请求进行过滤。

缓存雪崩
指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。

在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。

解决方案：

为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现；
为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。
也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。
缓存一致性
缓存一致性要求数据更新的同时缓存数据也能够实时更新。

解决方案：

在数据更新的同时立即去更新缓存；
在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新。
要保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据。

缓存 “无底洞” 现象
指的是为了满足业务要求添加了大量缓存节点，但是性能不但没有好转反而下降了的现象。

产生原因：缓存系统通常采用 hash 函数将 key 映射到对应的缓存节点，随着缓存节点数目的增加，键值分布到更多的节点上，导致客户端一次批量操作会涉及多次网络操作，这意味着批量操作的耗时会随着节点数目的增加而不断增大。此外，网络连接数变多，对节点的性能也有一定影响。

解决方案：

优化批量数据操作命令；
减少网络通信次数；
降低接入成本，使用长连接 / 连接池，NIO 等。



===============数据分布==================
哈希分布
哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上。例如有 N 个节点，数据的主键为 key，则将该数据分配的节点序号为：hash(key)%N。

传统的哈希分布算法存在一个问题：当节点数量变化时，也就是 N 值变化，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移。

顺序分布
将数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上。例如 User 表的 ID 范围为 1 ~ 7000，使用顺序分布可以将其划分成多个子表，对应的主键范围为 1 ~ 1000，1001 ~ 2000，...，6001 ~ 7000。

顺序分布相比于哈希分布的主要优点如下：

能保持数据原有的顺序；
并且能够准确控制每台服务器存储的数据量，从而使得存储空间的利用率最大。
七、一致性哈希

Distributed Hash Table（DHT） 是一种哈希分布方式，其目的是为了克服传统哈希分布在服务器节点数量变化时大量数据迁移的问题。

基本原理
将哈希空间 [0, 2n-1] 看成一个哈希环，每个服务器节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。

